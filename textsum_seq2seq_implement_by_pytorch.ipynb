{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import socket\n",
    "hostname = socket.gethostname()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence#, masked_cross_entropy\n",
    "from masked_cross_entropy import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA=torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USE_CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  获取字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_path='./vocab/vocab.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vocab(vocab_path):\n",
    "    vocab_list=[]\n",
    "    with open(vocab_path,'r',encoding='utf-8')as f:\n",
    "        for item in f.readlines():\n",
    "            vocab_list.append(item.strip())\n",
    "    int_to_vocab = {idx: word for idx, word in enumerate(vocab_list)}\n",
    "    vocab_to_int = {word: idx for idx, word in int_to_vocab.items()}\n",
    "    return int_to_vocab,vocab_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_int_to_letter, source_letter_to_int=get_vocab(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source_int_to_letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padded Batch\n",
    "### return input_var, input_lengths, target_var, target_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 给添加padded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_sentence_batch(sentence_batch, pad_int):\n",
    "    '''\n",
    "    对batch中的序列进行补全，保证batch中的每行都有相同的sequence_length\n",
    "    \n",
    "    参数：\n",
    "    - sentence batch\n",
    "    - pad_int: <PAD>对应索引号\n",
    "    '''\n",
    "    max_sentence = max([len(sentence) for sentence in sentence_batch])\n",
    "    return [sentence + [pad_int] * (max_sentence - len(sentence)) for sentence in sentence_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(file_list,tokenize_path,batch_size,pad_int):\n",
    "    '''\n",
    "    定义生成器，用来获取tokenize下的所有content\n",
    "    '''\n",
    "    for item in file_list:\n",
    "        source_path=os.path.join(tokenize_path,'content_'+item)\n",
    "        target_path=os.path.join(tokenize_path,'title_'+item)\n",
    "        with open(source_path,'r',encoding='utf-8')as sf:\n",
    "            sources=[[int(word) for word in sentence.strip().split(' ')]for sentence in sf.readlines()]\n",
    "        with open(target_path,'r',encoding='utf-8')as tf:\n",
    "            targets=[[int(word) for word in sentence.strip().split(' ')]for sentence in tf.readlines()]\n",
    "        \n",
    "        for batch_i in range(0, len(sources)//batch_size):\n",
    "            start_i = batch_i * batch_size\n",
    "            sources_batch = sources[start_i:start_i + batch_size]\n",
    "            targets_batch = targets[start_i:start_i + batch_size]\n",
    "            # 补全序列\n",
    "            pad_sources_batch = np.array(pad_sentence_batch(sources_batch, pad_int))\n",
    "            pad_targets_batch = np.array(pad_sentence_batch(targets_batch, pad_int))\n",
    "            \n",
    "            \n",
    "            # 记录每条记录的长度\n",
    "            targets_lengths = []\n",
    "            for target in targets_batch:\n",
    "                targets_lengths.append(len(target))\n",
    "\n",
    "            source_lengths = []\n",
    "            for source in sources_batch:\n",
    "                source_lengths.append(len(source))\n",
    "            \n",
    "            \n",
    "            #做一个降序\n",
    "            source_lengths=np.array(source_lengths)\n",
    "            targets_lengths=np.array(targets_lengths)\n",
    "            \n",
    "            index=np.argsort(-source_lengths)\n",
    "            source_lengths=source_lengths[index]\n",
    "            targets_lengths=targets_lengths[index]\n",
    "            pad_sources_batch=pad_sources_batch[index,:]\n",
    "            \n",
    "            pad_targets_batch=pad_targets_batch[index,:]\n",
    "            \n",
    "            pad_sources_batch=Variable(torch.LongTensor(pad_sources_batch)).transpose(0,1)\n",
    "            pad_targets_batch=Variable(torch.LongTensor(pad_targets_batch)).transpose(0,1)\n",
    "\n",
    "            if  USE_CUDA:\n",
    "                pad_sources_batch=pad_sources_batch.cuda()\n",
    "                pad_targets_batch=pad_targets_batch.cuda()\n",
    "            \n",
    "            \n",
    "    \n",
    "\n",
    "            #yield pad_targets_batch, pad_sources_batch, targets_lengths, source_lengths\n",
    "            yield pad_sources_batch, source_lengths, pad_targets_batch, targets_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=self.dropout, bidirectional=True)\n",
    "        \n",
    "    def forward(self, input_seqs, input_lengths, hidden=None):\n",
    "        # Note: we run this all at once (over multiple batches of multiple sequences)\n",
    "        embedded = self.embedding(input_seqs)\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs) # unpack (back to padded)\n",
    "        outputs, hidden = self.gru(embedded, hidden)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] # Sum bidirectional outputs\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing an attention module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class Attn(nn.Module):\n",
    "#     def __init__(self, method, hidden_size):\n",
    "#         super(Attn, self).__init__()\n",
    "        \n",
    "#         self.method = method\n",
    "#         self.hidden_size = hidden_size\n",
    "        \n",
    "#         if self.method == 'general':\n",
    "#             self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "#         elif self.method == 'concat':\n",
    "#             self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "#             self.v = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "#     def forward(self, hidden, encoder_outputs):\n",
    "#         max_len = encoder_outputs.size(0)\n",
    "#         this_batch_size = encoder_outputs.size(1)\n",
    "\n",
    "#         # Create variable to store attention energies\n",
    "#         attn_energies = Variable(torch.zeros(this_batch_size, max_len)) # B x S\n",
    "\n",
    "#         if USE_CUDA:\n",
    "#             attn_energies = attn_energies.cuda()\n",
    "\n",
    "#         # For each batch of encoder outputs\n",
    "#         for b in range(this_batch_size):\n",
    "#             # Calculate energy for each encoder output\n",
    "#             for i in range(max_len):\n",
    "#                 attn_energies[b, i] = self.score(hidden[:, b], encoder_outputs[i, b].unsqueeze(0))\n",
    "\n",
    "#         # Normalize energies to weights in range 0 to 1, resize to 1 x B x S\n",
    "#         return F.softmax(attn_energies).unsqueeze(1)\n",
    "    \n",
    "#     def score(self, hidden, encoder_output):\n",
    "        \n",
    "#         if self.method == 'dot':\n",
    "#             energy = hidden.dot(encoder_output)\n",
    "#             return energy\n",
    "        \n",
    "#         elif self.method == 'general':\n",
    "#             energy = self.attn(encoder_output)\n",
    "#             energy = hidden.dot(energy)\n",
    "#             return energy\n",
    "        \n",
    "#         elif self.method == 'concat':\n",
    "#             energy = self.attn(torch.cat((hidden, encoder_output), 1))\n",
    "#             energy = self.v.dot(energy)\n",
    "#             return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "            self.v = nn.Parameter(weight_init.xavier_uniform(torch.FloatTensor(1, self.hidden_size)))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        attn_energies = self.batch_score(hidden, encoder_outputs)\n",
    "        return F.softmax(attn_energies).unsqueeze(1)\n",
    "\n",
    "    def batch_score(self, hidden, encoder_outputs):\n",
    "        if self.method == 'dot':\n",
    "            encoder_outputs = encoder_outputs.permute(1, 2, 0)\n",
    "            energy = torch.bmm(hidden.transpose(0, 1), encoder_outputs).squeeze(1)\n",
    "        elif self.method == 'general':\n",
    "            length = encoder_outputs.size(0)\n",
    "            batch_size = encoder_outputs.size(1)\n",
    "            energy = self.attn(encoder_outputs.view(-1, self.hidden_size)).view(length, batch_size, self.hidden_size)\n",
    "            energy = torch.bmm(hidden.transpose(0, 1), energy.permute(1, 2, 0)).squeeze(1)\n",
    "        elif self.method == 'concat':\n",
    "            length = encoder_outputs.size(0)\n",
    "            batch_size = encoder_outputs.size(1)\n",
    "            attn_input = torch.cat((hidden.repeat(length, 1, 1), encoder_outputs), dim=2)\n",
    "            energy = self.attn(attn_input.view(-1, 2 * self.hidden_size)).view(length, batch_size, self.hidden_size)\n",
    "            energy = torch.bmm(self.v.repeat(batch_size, 1, 1), energy.permute(1, 2, 0)).squeeze(1)\n",
    "        return energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the Bahdanau et al. model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BahdanauAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
    "        super(BahdanauAttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        # Define parameters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.attn = Attn('concat', hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, word_input, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step at a time\n",
    "        # TODO: FIX BATCHING\n",
    "        \n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
    "        word_embedded = self.dropout(word_embedded)\n",
    "        \n",
    "        # Calculate attention weights and apply to encoder outputs\n",
    "        attn_weights = self.attn(last_hidden[-1], encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n",
    "        context = context.transpose(0, 1) # 1 x B x N\n",
    "        \n",
    "        # Combine embedded input word and attended context, run through RNN\n",
    "        rnn_input = torch.cat((word_embedded, context), 2)\n",
    "        output, hidden = self.gru(rnn_input, last_hidden)\n",
    "        \n",
    "        # Final output layer\n",
    "        output = output.squeeze(0) # B x N\n",
    "        output = F.log_softmax(self.out(torch.cat((output, context), 1)))\n",
    "        \n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout)\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # Choose attention model\n",
    "        if attn_model != 'none':\n",
    "            self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_seq, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step at a time\n",
    "\n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        batch_size = input_seq.size(0)\n",
    "        embedded = self.embedding(input_seq)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        embedded = embedded.view(1, batch_size, self.hidden_size) # S=1 x B x N\n",
    "\n",
    "        # Get current hidden state from input word and last hidden state\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "\n",
    "        # Calculate attention from current RNN state and all encoder outputs;\n",
    "        # apply to encoder outputs to get weighted average\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x S=1 x N\n",
    "\n",
    "        # Attentional vector using the RNN hidden state and context vector\n",
    "        # concatenated together (Luong eq. 5)\n",
    "        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
    "        context = context.squeeze(1)       # B x S=1 x N -> B x N\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = F.tanh(self.concat(concat_input))\n",
    "\n",
    "        # Finally predict next token (Luong eq. 6, without softmax)\n",
    "        output = self.out(concat_output)\n",
    "\n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path='./data_test'\n",
    "file_list=os.listdir(data_path)\n",
    "tokenize_path='./tokenize'\n",
    "batch_size=10\n",
    "pad_int=source_letter_to_int['<PAD>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batcher=get_batches(file_list,tokenize_path,batch_size,pad_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_batches, input_lengths, target_batches, target_lengths=next(batcher)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_batches torch.Size([98, 10])\n",
      "target_batches torch.Size([16, 10])\n"
     ]
    }
   ],
   "source": [
    "print('input_batches', input_batches.size()) # (max_len x batch_size)\n",
    "print('target_batches', target_batches.size()) # (max_len x batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "   824  32596    700    187    824   1749    824    390    390    824\n",
       " 28625  38464    110      4    402   9371   6690     29     29     98\n",
       " 15777  17980   2272      4   5926   7294   3687   1298   1298    309\n",
       " 28626  17981   1633      6    131      4   2531    147    147   4907\n",
       "  1070    675  23078      4  21060      4  23074   2112   2112    371\n",
       " 25495   1402  32599      4    367      6  47156      3      3   3848\n",
       "  8786    506   1527     69  21061      4   2532      0      0   1427\n",
       "  6033      1   2414    193   2766      4   8290      0      0  32591\n",
       " 14892  28627      3      5   3080    249   2144      0      0      3\n",
       " 38463    599      0    880   6034  19380      3      0      0      0\n",
       "     3      3      0   5427      3  14076      0      0      0      0\n",
       "     0      0      0   2322      0   2031      0      0      0      0\n",
       "     0      0      0   9370      0    511      0      0      0      0\n",
       "     0      0      0      3      0    100      0      0      0      0\n",
       "     0      0      0      0      0    599      0      0      0      0\n",
       "     0      0      0      0      0      3      0      0      0      0\n",
       "[torch.LongTensor of size 16x10]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([98, 94, 91, 87, 87, 86, 66, 59, 59, 24])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_hidden_size = 8\n",
    "small_n_layers = 2\n",
    "\n",
    "encoder_test = EncoderRNN(len(source_int_to_letter), small_hidden_size, small_n_layers)\n",
    "decoder_test = LuongAttnDecoderRNN('general', small_hidden_size, len(source_int_to_letter), small_n_layers)\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder_test.cuda()\n",
    "    decoder_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN(\n",
      "  (embedding): Embedding(50000, 8)\n",
      "  (gru): GRU(8, 8, num_layers=2, dropout=0.1, bidirectional=True)\n",
      ")\n",
      "LuongAttnDecoderRNN(\n",
      "  (embedding): Embedding(50000, 8)\n",
      "  (embedding_dropout): Dropout(p=0.1)\n",
      "  (gru): GRU(8, 8, num_layers=2, dropout=0.1)\n",
      "  (concat): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (out): Linear(in_features=8, out_features=50000, bias=True)\n",
      "  (attn): Attn(\n",
      "    (attn): Linear(in_features=8, out_features=8, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(encoder_test)\n",
    "print(decoder_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_outputs torch.Size([59, 3, 8])\n",
      "encoder_hidden torch.Size([4, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "encoder_outputs, encoder_hidden = encoder_test(input_batches, input_lengths, None)\n",
    "\n",
    "print('encoder_outputs', encoder_outputs.size()) # max_len x batch_size x hidden_size\n",
    "print('encoder_hidden', encoder_hidden.size()) # n_layers * 2 x batch_size x hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOS_token=source_letter_to_int['<GO>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 10.858139038085938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "C:\\Users\\Administrator\\Desktop\\NLP\\文本摘要\\textsum\\masked_cross_entropy.py:42: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_probs_flat = functional.log_softmax(logits_flat)\n",
      "C:\\Users\\Administrator\\Desktop\\NLP\\文本摘要\\textsum\\masked_cross_entropy.py:9: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.3. Note that arange generates values in [start; end), not [start; end].\n",
      "  seq_range = torch.range(0, max_len - 1).long()\n"
     ]
    }
   ],
   "source": [
    "max_target_length = max(target_lengths)\n",
    "\n",
    "# Prepare decoder input and outputs\n",
    "decoder_input = Variable(torch.LongTensor([SOS_token] * batch_size))\n",
    "decoder_hidden = encoder_hidden[:decoder_test.n_layers] # Use last (forward) hidden state from encoder\n",
    "all_decoder_outputs = Variable(torch.zeros(max_target_length, batch_size, decoder_test.output_size))\n",
    "\n",
    "if USE_CUDA:\n",
    "    all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "    decoder_input = decoder_input.cuda()\n",
    "\n",
    "# Run through decoder one time step at a time\n",
    "for t in range(max_target_length):\n",
    "    decoder_output, decoder_hidden, decoder_attn = decoder_test(\n",
    "        decoder_input, decoder_hidden, encoder_outputs\n",
    "    )\n",
    "    all_decoder_outputs[t] = decoder_output # Store this step's outputs\n",
    "    decoder_input = target_batches[t] # Next input is current target\n",
    "\n",
    "# Test masked cross entropy loss\n",
    "loss = masked_cross_entropy(\n",
    "    all_decoder_outputs.transpose(0, 1).contiguous(),\n",
    "    target_batches.transpose(0, 1).contiguous(),\n",
    "    target_lengths\n",
    ")\n",
    "print('loss', loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "   390    390    824\n",
       "    29     29     98\n",
       "  1298   1298    309\n",
       "   147    147   4907\n",
       "  2112   2112    371\n",
       "     3      3   3848\n",
       "     0      0   1427\n",
       "     0      0  32591\n",
       "     0      0      3\n",
       "[torch.LongTensor of size 9x3]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "step=len(target_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Variable containing:\n",
      " 10.8624\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "2 Variable containing:\n",
      " 10.8990\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "1 Variable containing:\n",
      " 10.8782\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "2 Variable containing:\n",
      " 10.9051\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "1 Variable containing:\n",
      " 10.7996\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "2 Variable containing:\n",
      " 10.7996\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss=0\n",
    "for i in range(3):\n",
    "    print('1',F.cross_entropy(all_decoder_outputs[:,i,:],target_batches[:,i]))\n",
    "    print('2',F.cross_entropy(all_decoder_outputs[:,i,:],target_batches[:,i],ignore_index=0))\n",
    "    loss+=F.cross_entropy(all_decoder_outputs[:,i,:],target_batches[:,i],ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 10.8467\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss=0.0\n",
    "for i in  range(step):\n",
    "    loss+=F.cross_entropy(all_decoder_outputs[i],target_batches[i],ignore_index=0,reduce=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "  7.2660\n",
       "  7.2701\n",
       " 10.7996\n",
       "[torch.FloatTensor of size 3]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss/step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOS_token=source_letter_to_int['<GO>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(input_batches, input_lengths, target_batches, target_lengths, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    \n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 # Added onto for each word\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_batches, input_lengths, None)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = Variable(torch.LongTensor([SOS_token] * batch_size))\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
    "\n",
    "    max_target_length = max(target_lengths)\n",
    "    all_decoder_outputs = Variable(torch.zeros(max_target_length, batch_size, decoder.output_size))\n",
    "\n",
    "    # Move new Variables to CUDA\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "\n",
    "    # Run through decoder one time step at a time\n",
    "    for t in range(max_target_length):\n",
    "        decoder_output, decoder_hidden, decoder_attn = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs\n",
    "        )\n",
    "\n",
    "        all_decoder_outputs[t] = decoder_output\n",
    "        decoder_input = target_batches[t] # Next input is current target\n",
    "\n",
    "    # Loss calculation and backpropagation\n",
    "    loss = masked_cross_entropy(\n",
    "        all_decoder_outputs.transpose(0, 1).contiguous(), # -> batch x seq\n",
    "        target_batches.transpose(0, 1).contiguous(), # -> batch x seq\n",
    "        target_lengths\n",
    "    )\n",
    "    loss.backward()\n",
    "    \n",
    "    # Clip gradient norms\n",
    "    ec = torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    dc = torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "\n",
    "    # Update parameters with optimizers\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0], ec, dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_ver2(input_batches, input_lengths, target_batches, target_lengths, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    \n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 # Added onto for each word\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_batches, input_lengths, None)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = Variable(torch.LongTensor([SOS_token] * batch_size))\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
    "\n",
    "    max_target_length = int(max(target_lengths))\n",
    "    all_decoder_outputs = Variable(torch.zeros(max_target_length, batch_size, decoder.output_size))\n",
    "    loss=Variable(torch.FloatTensor([0]))\n",
    "    # Move new Variables to CUDA\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "        loss=loss.cuda()\n",
    "    # Run through decoder one time step at a time\n",
    "    for t in range(max_target_length):\n",
    "        decoder_output, decoder_hidden, decoder_attn = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs\n",
    "        )\n",
    "\n",
    "        all_decoder_outputs[t] = decoder_output\n",
    "        decoder_input = target_batches[t] # Next input is current target\n",
    "\n",
    "    # Loss calculation and backpropagation\n",
    "#     loss = masked_cross_entropy(\n",
    "#         all_decoder_outputs.transpose(0, 1).contiguous(), # -> batch x seq\n",
    "#         target_batches.transpose(0, 1).contiguous(), # -> batch x seq\n",
    "#         target_lengths\n",
    "#     )\n",
    "    \n",
    "    \n",
    "    for k in range(max_target_length):\n",
    "        #print(F.cross_entropy(all_decoder_outputs[k],target_batches[k],ignore_index=source_letter_to_int['<PAD>']))\n",
    "        loss+=F.cross_entropy(all_decoder_outputs[k],target_batches[k],ignore_index=source_letter_to_int['<PAD>'])\n",
    "    loss=loss/max_target_length\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    # Clip gradient norms\n",
    "    ec = torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    dc = torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "\n",
    "    # Update parameters with optimizers\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0], ec, dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Running training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configure models\n",
    "attn_model = 'dot'\n",
    "hidden_size = 50\n",
    "n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 32\n",
    "\n",
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "learning_rate = 0.001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_epochs = 200\n",
    "epoch = 0\n",
    "plot_every = 1\n",
    "print_every = 1\n",
    "evaluate_every = 1000\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderRNN(len(source_int_to_letter), hidden_size, n_layers, dropout=dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, hidden_size, len(source_int_to_letter), n_layers, dropout=dropout)\n",
    "\n",
    "# Initialize optimizers and criterion\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Move models to GPU\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "\n",
    "# import sconce\n",
    "# job = sconce.Job('seq2seq-translate', {\n",
    "#     'attn_model': attn_model,\n",
    "#     'n_layers': n_layers,\n",
    "#     'dropout': dropout,\n",
    "#     'hidden_size': hidden_size,\n",
    "#     'learning_rate': learning_rate,\n",
    "#     'clip': clip,\n",
    "#     'teacher_forcing_ratio': teacher_forcing_ratio,\n",
    "#     'decoder_learning_ratio': decoder_learning_ratio,\n",
    "# })\n",
    "# job.plot_every = plot_every\n",
    "# job.log_every = print_every\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job 5aa78360021bfb51e3803113 at 2018-03-13 15:56:33\n"
     ]
    }
   ],
   "source": [
    "import sconce\n",
    "job = sconce.Job('seq2seq-translate', {\n",
    "    'attn_model': attn_model,\n",
    "    'n_layers': n_layers,\n",
    "    'dropout': dropout,\n",
    "    'hidden_size': hidden_size,\n",
    "    'learning_rate': learning_rate,\n",
    "    'clip': clip,\n",
    "    'teacher_forcing_ratio': teacher_forcing_ratio,\n",
    "    'decoder_learning_ratio': decoder_learning_ratio,\n",
    "})\n",
    "job.plot_every = plot_every\n",
    "job.log_every = print_every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path='./data_test'\n",
    "file_list=os.listdir(data_path)\n",
    "tokenize_path='./tokenize'\n",
    "pad_int=source_letter_to_int['<PAD>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN(\n",
      "  (embedding): Embedding(50000, 200)\n",
      "  (gru): GRU(200, 200, num_layers=2, dropout=0.1, bidirectional=True)\n",
      ")\n",
      "LuongAttnDecoderRNN(\n",
      "  (embedding): Embedding(50000, 200)\n",
      "  (embedding_dropout): Dropout(p=0.1)\n",
      "  (gru): GRU(200, 200, num_layers=2, dropout=0.1)\n",
      "  (concat): Linear(in_features=400, out_features=200, bias=True)\n",
      "  (out): Linear(in_features=200, out_features=50000, bias=True)\n",
      "  (attn): Attn(\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(encoder)\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:325: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch._C' has no attribute '_cuda_getDevice'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-7a52b88572bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./model/encoder3.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mroot_key\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                 deserialized_objects[root_key] = restore_location(\n\u001b[1;32m--> 389\u001b[1;33m                     data_type(size), location)\n\u001b[0m\u001b[0;32m    390\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mview_metadata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[1;34m(self, device, async)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprev_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprev_idx\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_setDevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch._C' has no attribute '_cuda_getDevice'"
     ]
    }
   ],
   "source": [
    "encoder.load_state_dict(torch.load('./model/encoder3.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %fs' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取文件时间：  0m 0.129091s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-eeeee23e3038>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprof\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mnow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'计算返回时间： '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mas_minutes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\autograd\\profiler.py\u001b[0m in \u001b[0;36m__str__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_events\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;34m'<unfinished torch.autograd.profile>'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_events\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_finish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\autograd\\profiler.py\u001b[0m in \u001b[0;36m__str__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort_by\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\autograd\\profiler.py\u001b[0m in \u001b[0;36mtable\u001b[1;34m(self, sort_by)\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mstring\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \"\"\"\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbuild_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort_by\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexport_chrome_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\autograd\\profiler.py\u001b[0m in \u001b[0;36mbuild_table\u001b[1;34m(events, sort_by, header)\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mevt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         append(row_format.format(evt.key, evt.cpu_time_str, evt.cuda_time_str,\n\u001b[1;32m--> 474\u001b[1;33m                                  evt.count, evt.cpu_time_total_str, evt.cuda_time_total_str))\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\autograd\\profiler.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m         \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    462\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eca=0\n",
    "dca=0\n",
    "start=time.time()\n",
    "while epoch < n_epochs:\n",
    "    epoch += 1\n",
    "    \n",
    "    # Get training data for this cycle\n",
    "    for batch_i, (input_batches, input_lengths, target_batches, target_lengths) in enumerate(\n",
    "                get_batches(file_list,tokenize_path,batch_size,pad_int)):\n",
    "            \n",
    "        #print(input_batches)\n",
    "    #input_batches, input_lengths, target_batches, target_lengths = random_batch(batch_size)\n",
    "        now=time.time()\n",
    "        print('读取文件时间： ',as_minutes(now-start))\n",
    "        start=time.time()\n",
    "        #with torch.autograd.profiler.profile() as prof:\n",
    "        # Run the train function\n",
    "        loss, ec, dc = train_ver2(\n",
    "            input_batches, input_lengths, target_batches, target_lengths,\n",
    "            encoder, decoder,\n",
    "            encoder_optimizer, decoder_optimizer, criterion\n",
    "        )\n",
    "\n",
    "        # Keep track of loss\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        eca += ec\n",
    "        dca += dc\n",
    "\n",
    "        job.record(batch_i, loss)\n",
    "        #print(prof)\n",
    "        now=time.time()\n",
    "        print('计算返回时间： ',as_minutes(now-start))\n",
    "        start=time.time()\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model(encoder_path,decoder_path,flag):\n",
    "    encoder.load_state_dict(torch.load(encoder_path))\n",
    "    decoder.load_state_dict(torch.load(decoder_path))\n",
    "    encoder.train(flag)\n",
    "    decoder.train(flag)\n",
    "    return encoder,decoder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder,decoder=load_model('./model/encoder5.pkl','./model/decoder5.pkl',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_to_seq(text):\n",
    "    '''\n",
    "    对源数据进行转换\n",
    "    '''\n",
    "    sequence_length = 120\n",
    "    seq=[source_letter_to_int.get(word, source_letter_to_int['<UNK>']) for word in text.split(' ')] + [source_letter_to_int['<PAD>']]*(sequence_length-len(text))\n",
    "    seq=Variable(torch.LongTensor(seq))\n",
    "    return seq.unsqueeze(0).transpose(0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text='''\n",
    "郝海东 职业化 后 遭遇 重罚 第一 人   DATE   的 曼谷 亚运会 上 郝海东 在 比赛 中 不 服从 裁判 并 向 一名 边裁 吐口 水 亚足联 当时 就 对 他 禁赛   NUMBER   场 后来 又 追加 处罚 被 禁赛   DATE   这是 迄今为止 国脚 遭到 的 最 严厉 的 处罚 郝海东 的 这次 被 禁赛 的 范围 非常 广 这 其中 也 包括 了 国内 的 联赛 等 国内外 的 一切 正式 比赛 所幸 郝海东 本身 就是 个 天才 并 没有 因\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, max_length=120):\n",
    "    EOS_token=source_letter_to_int['<EOS>']\n",
    "    #input  output\n",
    "    input_variable = source_to_seq(text)\n",
    "    input_length = [input_variable.size()[0]]\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]])) # SOS\n",
    "    encoder_hidden = Variable(torch.zeros(n_layers*2, 1, hidden_size))\n",
    "\n",
    "    if USE_CUDA:\n",
    "        input_variable=input_variable.cuda()\n",
    "        decoder_input=decoder_input.cuda()\n",
    "        encoder_hidden=encoder_hidden.cuda()\n",
    "    \n",
    "    # Run through encoder\n",
    "    #encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable,input_length, encoder_hidden)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]])) # SOS\n",
    "    decoder_hidden = encoder_hidden[:n_layers]\n",
    "    \n",
    "    \n",
    "    \n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    \n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        \n",
    "        #print(decoder_attentions[di,:decoder_attention.size(2)])\n",
    "        decoder_attentions[di,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "\n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(source_int_to_letter[ni])\n",
    "            \n",
    "        # Next input is chosen word\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    return decoded_words, decoder_attentions[:di+1, :len(encoder_outputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "word,att=evaluate(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "鸟巢 十大 事件 中 事件 国奥 一战 成名 多 成名 最 恶劣 <EOS>\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29fbd1114e0>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6IAAACeCAYAAAAoqLfMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGedJREFUeJzt3XmMZFd1x/Hfqeru6WUW25jVNhlHAhMLJQGNCEtEIkwk\nswjzR5SARASEaKRsGESEIPkD5Y9ISCAEEogwMpsEAkWGCIQIwWERRCIWg40CeCCAAc8YL2OG2Xq6\nu6r6nfzRBQyD3fc3Xbdf9VR9P5Ll6Zoz591677z73u1aTmSmAAAAAABoS2fcAwAAAAAATBcWogAA\nAACAVrEQBQAAAAC0ioUoAAAAAKBVLEQBAAAAAK1iIQoAAAAAaNXYFqIRcWNEfC8ifhARbxrXOIDt\nFBHXRMSXIuKuiPhORNw8fPyKiLgtIr4//P/l4x4rUFtEdCPizoj4zPBn6h4TLSIui4hbI+K7EXEk\nIp5F3WPSRcTrh/c4346Ij0XEPHUPx1gWohHRlfQeSS+QdL2kl0fE9eMYC7DNBpLekJnXS3qmpL8d\n1vqbJH0hM58k6QvDn4FJc7OkI+f9TN1j0r1L0ucy8ymSfk8b9U/dY2JFxFWSXivpQGY+VVJX0stE\n3cMwrldEnyHpB5l5d2b2JH1c0k1jGguwbTLzvsy8Y/jnM9q4KblKG/X+4WHYhyW9dDwjBLZHRFwt\n6UWSbjnvYeoeEysi9kl6rqT3S1Jm9jLzpKh7TL4ZSQsRMSNpUdJPRd3DMK6F6FWSjp7387HhY8DE\nioj9kp4m6XZJj83M+4Z/db+kx45pWMB2eaekN0pqznuMuscku1bScUkfHL4l/ZaIWBJ1jwmWmfdK\nerukeyTdJ+lUZn5e1D0MfFkR0IKI2C3pE5Jel5mnz/+7zExJOZaBAdsgIl4s6cHM/MYjxVD3mEAz\nkp4u6b2Z+TRJy7rg7YjUPSbN8LOfN2njFzFPkLQUEa84P4a6xyMZ10L0XknXnPfz1cPHgIkTEbPa\nWIR+NDM/OXz4gYh4/PDvHy/pwXGND9gGz5H0koj4sTY+evG8iPiIqHtMtmOSjmXm7cOfb9XGwpS6\nxyR7vqQfZebxzOxL+qSkZ4u6h2FcC9GvS3pSRFwbEXPa+FDzp8c0FmDbRERo4/NCRzLzHef91acl\nvXL451dK+lTbYwO2S2a+OTOvzsz92pjfv5iZrxB1jwmWmfdLOhoR1w0fukHSXaLuMdnukfTMiFgc\n3vPcoI3vw6DuURQbr5aPYcMRL9TGZ4i6kj6Qmf8yloEA2ygi/lDSVyV9S7/6rNw/auNzov8m6YmS\nfiLpzzLzxFgGCWyjiPhjSf+QmS+OiEeJuscEi4jf18YXdM1JulvSq7XxS3/qHhMrIv5Z0p9ro1PA\nnZL+StJuUfcoGNtCFAAAAAAwnfiyIgAAAABAq1iIAgAAAABaxUIUAAAAANAqFqIAAAAAgFaxEAUA\nAAAAtGrsC9GIODjuMQBto+4xjah7TCPqHtOIuodj7AtRSRQqphF1j2lE3WMaUfeYRtQ9inbCQhQA\nAAAAMEUiM1vb2Fzsynkt/dpjfa1pVrsuPlk4IUaQpJp7IMLbpsM7NubonTB76PWeo1qsP+kijk/H\n+B3NCGPv5armYn7L/35T7nN0xu8+x7nZcsz6upfLqa+mMXM5mzP3V8WyV1Per/7c7BxHM5WxL0bZ\nDT2tae78+b5r/i7UeYp2TVTcX46adVP3YmWGGXHucXRyGefGxja7Ri5vzllfKt+DdFcHVq5cXfuN\nx7bzPsfW7qUW41TxPnSU+5zfqPuK95juvZx1HW35PnRanNHPH8rMR5fiZkbZSETcKOldkrqSbsnM\nt24WP68l/UHn+aNs8lfbNi5CMeM9vVw3bmA65kXb2aZZ9Nk3Lnzp3XylcXEP8zkq6r2Qns7ixHyO\nzrg6zoJJUiwsFGOy17NyWZyFr2Qt5sJ8jlbd9/tWrrjmCeWgEyetXDLOoTy77OUyzrXYZd4gOueH\ne3FcK9fOw93QPnxg+Tg6579kzqvuosPZ3tKiF2jUfbOyWi2XNS9J1pxjz6uGquOa9a6PzjWts2e3\nlUuz5bnJrvvL9xZD4vRZK9XpZ+8vxuw5csLKtf69u604R9XaGRj3E+NYwNTcZk01Fyc1n6Nzbju/\npDHZc47Bruea9/e98j2M/Ryde1EWtb/0X3nrT5y4Ld9RRERX0nskvUDS9ZJeHhHXbzUfAAAAAGA6\njPKr7WdI+kFm3p2ZPUkfl3RTnWEBAAAAACbVKAvRqyQdPe/nY8PHAAAAAAB4RCN9RtQx7CN0UJLm\nZX4eCAAAAAAwsUZ5RfReSdec9/PVw8d+TWYeyswDmXlgS98aBwAAAACYKKMsRL8u6UkRcW1EzEl6\nmaRP1xkWAAAAAGBSbfmtuZk5iIi/k/Sf2mjf8oHM/E61kQEAAAAAJtJInxHNzM9K+uxF/qNRNvmr\nNEZPLL83UL2+P7lm9kDbgdx2nTtWGr0GV82aWDV7ErbN6Ue2srL947hA9/jPijGxtGTlWn+onMvu\n4eqc2+fOebmmQDZGj02vtazHPc+cuh9H/zZjzqk6r7r9CJ3juObNhc41rTHPoZibK8eYPRDjsj3F\nmPXHX2nl+uq731eM+Z33/Y2Va//bfuMTSr/JPI6dy/aVgxqvwNZP/NyKc4QxfqtPtaTOktOz25t0\nnOuC34u35Z6qNc9tI2Yc7LnQ6HtdtY+7ix6h26JeZ3IAAAAAAAwsRAEAAAAArWIhCgAAAABoFQtR\nAAAAAECrWIgCAAAAAFrFQhQAAAAA0CoWogAAAACAVrEQBQAAAAC0aqb1LXY2b1btNrNWp9z812me\nLUm5slKOcZsgWxu8xJvi1mz0XFOUf68Ss17JOw27XWkcb7vuW973sTDvxe0tN5dvdpu5Tp8pxmR/\nYOVS7szG3pe0ijVo173BnqN36vzr7Fdjjtvgdo5vmdOovjHP7fuPF0M6896c84w3/3UxZv+dJ6xc\nTh12Fhe9XIvl8ecu7z7HmVfV8eqrY8z32etbuZr9jyvGdI+fsnLlKePasbbm5er1ykHu/GXUvS3r\nndtV72svYTEz6wXW3PdOTVTcXlXudcgsL14RBQAAAAC0assL0Yi4JiK+FBF3RcR3IuLmmgMDAAAA\nAEymUd6aO5D0hsy8IyL2SPpGRNyWmXdVGhsAAAAAYAJt+RXRzLwvM+8Y/vmMpCOSrqo1MAAAAADA\nZKryGdGI2C/paZJur5EPAAAAADC5Rv7W3IjYLekTkl6Xmacf5u8PSjooSfPyvikOAAAAADC5RnpF\nNCJmtbEI/WhmfvLhYjLzUGYeyMwDs9o1yuYAAAAAABNglG/NDUnvl3QkM99Rb0gAAAAAgEk2yiui\nz5H0F5KeFxHfHP73wkrjAgAAAABMqC1/RjQz/1tSXMy/iW5H3d1Lm+ft9axczdpaMcbNpUwvDhtq\n7q+4qBLaXDblmPV1K1VjxlmiyneCbaTqdssxM95pnYOBEeQd62bPQjHm1FP2Wbn2GYex+8DPrFy5\nvFyOMY911KxVQ9Pr10vmnBvy6sut5+iW49KsL6umzf2Vg4r71dgX0fHqxnmOUbh+/kKurBpB5jze\nlGvHmkskydgX2TdzrayUY8xz+9FfPFqMyXPnrFzZGPvVnKPjXPk4xpnyHCdJ684xcsYuad3Z985c\nIql7rByXRg1uJDPmHLO+nOMYYZ5D5hxgaYz515zvrbnczVWTs82K96HZN9cKFe8BrGutvHPIOde8\n7UkxN2sEmfe0J7ywenfIAAAAAAAYWIgCAAAAAFrFQhQAAAAA0CoWogAAAACAVrEQBQAAAAC0ioUo\nAAAAAKBVLEQBAAAAAK1iIQoAAAAAaJXXVbmW6EgL85vHuA3OjebMVmNpSUqv6TW2Qc2Gyk4ut6mv\nt8VqYm7OjDOaDXfM5+g0Qd69ZOXSoHyMFh7qW6k6y+Vm6XYDaqcRutn0Pp36MhuXu82lq3EbUBtx\nYTSNlyR1jFxuo/q2ufvLYF+HjGuazpXPDUlW3afbEN4Yv/0cG+M5mvO9c9nO1TUrl35W7rye7jzh\nxDnHWpK1V905J8px6ZZ9Y5zbxvYkSbvK175Y8+b7mvtLzuGuuO9d6T3LS5s7N0069351pryUs+8x\nlxbLQe7xKU+rknhFFAAAAADQspEXohHRjYg7I+IzNQYEAAAAAJhsNV4RvVnSkQp5AAAAAABTYKSF\naERcLelFkm6pMxwAAAAAwKQb9RXRd0p6o6Qd+o0TAAAAAICdZssL0Yh4saQHM/MbhbiDEXE4Ig73\nGvMb/wAAAAAAE2uUV0SfI+klEfFjSR+X9LyI+MiFQZl5KDMPZOaBuc7CCJsDAAAAAEyCLS9EM/PN\nmXl1Zu6X9DJJX8zMV1QbGQAAAABgItFHFAAAAADQqpkaSTLzy5K+bARKvf7mMf3C3/8i1fq6EZRW\nLoxRGt9z5R7HLNdE9szv1Wq5dnL5nBUXq91yUCe8jTrn0NllK1Xn2muKMf09xtglze1bKm/PyiRF\nab6RlAu7vFxny8eoMY+jte+dc0OqWqvZGOfQwKuv6HrHu1aumDUvZ85+jXq/o7WuVZKyMY6jmcsR\nYc4Ts+3OOcY0vsE4Rm4Nxq7yHBBdsyaMOSd2zVmp0jm3nbqRFAvGR6N6PStXs7JaDnJroj8ox7hz\n3MDI5Z5DzjzhnttOHZrH0RmXNZeYuWrOhb6K94XTwNkXbq06azC3vky8IgoAAAAAaBULUQAAAABA\nq1iIAgAAAABaxUIUAAAAANAqFqIAAAAAgFaxEAUAAAAAtIqFKAAAAACgVSxEAQAAAACtMjuAV9I0\nypWVzWM63tq44zRnNptZF8ckvyk5TXYv0k7dX0azd7dZusVtvG41xjaaQUtKp1G125TcaPY+/+Ca\nlapz/8+KMc2Zs1Yup76it2SlapaXyzGr3nO07NRzwxyXNWeazdLDyJXmuGJurpyrP7By5cBo/l3x\nOOaaeR0y5i/r/JcUxhyQNRucu+Ny5kJ3/nrUZV6c4+TpYkgOvPpy9kXMmPc5xr7o7N1t5Yqz5blQ\nHW9c/f2PKcbMPHDKyqWfl+Oc81+S0pnL3Vp1zkf3ZSFnWnXvfQfle4WYrbhMMO+js3F2hnefU5Vz\nPppzjjNnhnOw5V1rs9ezcmmtXPdOPV8MXhEFAAAAALRqpIVoRFwWEbdGxHcj4khEPKvWwAAAAAAA\nk2nU19zfJelzmfmnETEnabHCmAAAAAAAE2zLC9GI2CfpuZJeJUmZ2ZNkvgkZAAAAADCtRnlr7rWS\njkv6YETcGRG3RIT3rR8AAAAAgKk1ykJ0RtLTJb03M58maVnSmy4MioiDEXE4Ig73VPEbJQEAAAAA\nl6RRFqLHJB3LzNuHP9+qjYXpr8nMQ5l5IDMPzGnXCJsDAAAAAEyCLS9EM/N+SUcj4rrhQzdIuqvK\nqAAAAAAAE2vUb839e0kfHX5j7t2SXj36kAAAAAAAk2ykhWhmflPSAX9rM+pc+ajNc+7bbaVqFufK\nMXNdb1jfvaec6/RZK1eur5eDGiNmJ4uomMt4UT6bettzGeOKuXINSpKa8vhjYcHLNTdbDMlzK16u\nrPcl183d5XOoa9bNoNcvB9WsiRVzfzkyvbia59AUSHe/OrrGdcGZx3cyZ3+l9xwzjVqteXxMWfE6\num7MXzWFU4OS1Cnv+5gxb+OMY+ReO8K4DjkxkjR774lyUH9g5crGqEPjeixJ4ez7WW/fW/ti3bym\n9Y3r46y377VaDuns8e7JndqxZ4nGON41r7XOfaikjlX33n1hs1b+zhw3lzUHmOdjzBsfoXTnrx96\nYaN8RhQAAAAAgIvGQhQAAAAA0CoWogAAAACAVrEQBQAAAAC0ioUoAAAAAKBVLEQBAAAAAK1iIQoA\nAAAAaBULUQAAAABAq8xOyHXkbFfrj7t805juibNWrvjR0WJMx2yCvD4wGgS7xtDYu3U1n6PRa9jm\njMtpbixJRrP0ZsVr/u00Sw5zn3Zyvhy0bjZ6d5p/19T19r3V7D3rFY7VBH0jsBzj1pfTQDvN49g2\n8zk6x9Hd907DbqtuJOWgfF1wc2mm3CQ8+z0vl8OtL1wcY763OcfInb8aY55w53tDmvdMzfK5YkzM\nLlu5nHNbHe81k+iW45zzX/LmJvtsdO4BwpsLnajsmXOOcU3Ls95xzHXj+uhcQy8mzspl7DHzWpuD\n8hG39oOkmC3XfWf3kpVr/aorizHLT/Ryre4r1+rCz80554deGK+IAgAAAABaNdJCNCJeHxHfiYhv\nR8THIsJ4uQYAAAAAMM22vBCNiKskvVbSgcx8qqSupJfVGhgAAAAAYDKN+tbcGUkLETEjaVHST0cf\nEgAAAABgkm15IZqZ90p6u6R7JN0n6VRmfr7WwAAAAAAAk2mUt+ZeLukmSddKeoKkpYh4xcPEHYyI\nwxFxuD8of9MaAAAAAGCyjfLW3OdL+lFmHs/MvqRPSnr2hUGZeSgzD2TmgdmZxRE2BwAAAACYBKMs\nRO+R9MyIWIyIkHSDpCN1hgUAAAAAmFSjfEb0dkm3SrpD0reGuQ5VGhcAAAAAYELNjPKPM/Mtkt7i\nxkdvoM7RBzfPuW+Pt+3rf7sY0+zynt7MD8pf9tucPGXl0vp6MSQHAy/XThUx7hE8vJrj6nTLIUvm\nW82Nmohdu6xUsWuuGJPrjZerKcdlppXL4eZKY38pvedYVcV9IY1h/LXUPI5h/i7UmVfNccXiQjnX\nyqqVKwd9K66aqjWIX6p57XBrupZu+Volyaqdzrx3HXKuMTHvtZWPudny9nrmeWbcW8Vc+RoqSeob\nuWbMW2gnzr2mdcr11THH1aytFWNij3dPruXlYoh1TZCkxpjn0szlnNvmOevUjlsTjXGNac6W96kk\ndX5YPo57jpbPM0na64y/8hqg5RkTAAAAADDtWIgCAAAAAFrFQhQAAAAA0CoWogAAAACAVrEQBQAA\nAAC0ioUoAAAAAKBVLEQBAAAAAK1iIQoAAAAAaJXZjbeS2Rnlo6/YNKRz8oyVKu65txjTMZouS9J6\nzabk09BwvOZzrNkX1xmX24i3KTdLbs6e9XIZzZLDbPRs/eao8ereaUqujrm/nPGbjdfD2qbZxN1g\nN9luu+m927C7be5+sJ5jvSbuMec17E6jkbizPUmKmfI2s9+zcnkbrFiD7jzubPNSv+5VHb9T0+b8\n5c6/DuM4Ns65ISn7g2JMp+/dV+Wscd6a17SYLd/SOmOXvOtCmnVjXdPM66OiPP7smXOO8xzPePfk\n1v2EO98b91825xiZ19pmda0YE12vvqJrXNMWF6xczTWPKcacevJuL9dMuVaX7jfXTEe9MF4RBQAA\nAAC0qrgQjYgPRMSDEfHt8x67IiJui4jvD/9/+fYOEwAAAAAwKZxXRD8k6cYLHnuTpC9k5pMkfWH4\nMwAAAAAARcWFaGZ+RdKJCx6+SdKHh3/+sKSXVh4XAAAAAGBCbfUzoo/NzPuGf75f0mMrjQcAAAAA\nMOFG/rKi3PjasEf8WqqIOBgRhyPicG+wPOrmAAAAAACXuK0uRB+IiMdL0vD/Dz5SYGYeyswDmXlg\nbmZpi5sDAAAAAEyKrS5EPy3plcM/v1LSp+oMBwAAAAAw6Zz2LR+T9DVJ10XEsYh4jaS3SvqTiPi+\npOcPfwYAAAAAoGimFJCZL3+Ev7rhorfW6yvufWDzmN3m23efvL8cs2vWSjVz9BHfWfxLzfI5K5f6\n/XKutTUvV035iB/jvXgR9XJlY8RUHLvLeI6dhYV6m5spnoobcfO7ijE5GHgb7RjHsTH3fRhvrjBz\n5fq6EeSOy3iO46ivNJ7jTuXuL+c5mnNJ9s2aNsSe3eWglVUrVzMoz/dVjaVWx7DNnci97jlzYUUx\n6107rFwL815gr1z3sW+vl2umWwzJk6e9XIaY8+4LNSgf71j07gFibq4YY59lHWPfmzWRy+X7r9iz\nx8ql5fJ3wNjzeNvX7U65BiWp49RO18uVzjrgrPe9Op0f3luMueI+837VuP/KyteEdmdMAAAAAMDU\nYyEKAAAAAGgVC1EAAAAAQKtYiAIAAAAAWsVCFAAAAADQKhaiAAAAAIBWsRAFAAAAALSKhSgAAAAA\noFX1OiEbsllXc+bM5jEnT3rJjtZrqFqvVfqUuJQbnFcce3PuXLVctsL5I6n1huqSFEYTZ7eReHTr\njT+WFssxRrNxScqm3PxbTpNqSXrMlcWQ5ifHrFRWk/A0xu4y6ys65abkaTTPlqTO3t3loCsus3Lp\nZPkcCjPXjBG3ft8DVi6nkbh9bhvHO5sxzOONd7x3opipN391LtvnbXSx3IS+9wSvVvt7y+OfPd23\ncnVvv6sY0zHOf0kKZ1+Y80Ts3VOMsa/bxjabk6esVBHGXOjemzjjGtS7q10/frxarh3LnJea1Yrz\nl1MTK6tWqk7Ne3Ln2tHz5gkXr4gCAAAAAFpVXIhGxAci4sGI+PZ5j70tIr4bEf8bEf8eEeavogEA\nAAAA0855RfRDkm684LHbJD01M39X0v9JenPlcQEAAAAAJlRxIZqZX5F04oLHPp+Zv3gT+v9Iunob\nxgYAAAAAmEA1PiP6l5L+o0IeAAAAAMAUGOlbcyPin7TxpbMf3STmoKSDkjSv8jdYAgAAAAAm25YX\nohHxKkkvlnRDbvK905l5SNIhSdrbueIS7vsBAAAAAKhhSwvRiLhR0hsl/VFmjqGZIgAAAADgUuW0\nb/mYpK9Jui4ijkXEayS9W9IeSbdFxDcj4l+3eZwAAAAAgAkRm7yrtv7GIo5L+skFD18p6aHWBgHs\nDNQ9phF1j2lE3WMaUffT7bcy89GloFYXog87gIjDmXlgrIMAWkbdYxpR95hG1D2mEXUPR432LQAA\nAAAA2FiIAgAAAABatRMWoofGPQBgDKh7TCPqHtOIusc0ou5RNPbPiAIAAAAApstOeEUUAAAAADBF\nWIgCAAAAAFrFQhQAAAAA0CoWogAAAACAVrEQBQAAAAC06v8BRprNQ+C/CzYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29fb057ff28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#output_words, attentions = evaluate(\"je suis trop froid .\")\n",
    "plt.matshow(att.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
